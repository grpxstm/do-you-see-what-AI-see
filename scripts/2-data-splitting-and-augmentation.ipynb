{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data splitting & augmentation\n",
    "\n",
    "Before we train any ML model on our data (ACRIMA dataset), we will first split the data into training & validation sets which can later be augmented using keras' `ImageDataGenerator` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Create new directories to separate the train & validation datasets\n",
    "acrima_dir = os.path.join(current_dir, \"data/acrima-dataset\")\n",
    "new_directories = [\"train\", \"validation\"]\n",
    "new_subdirectories = [\"glaucoma\", \"normal\"]\n",
    "\n",
    "for directory in new_directories:\n",
    "    new_directory_path = os.path.join(acrima_dir, directory)\n",
    "    if os.path.isdir(new_directory_path) == False:\n",
    "        os.makedirs(new_directory_path)\n",
    "\n",
    "    for subdirectory in new_subdirectories:\n",
    "        new_subdirectory_path = os.path.join(new_directory_path, subdirectory)\n",
    "        if os.path.isdir(new_subdirectory_path) == False:\n",
    "            os.makedirs(new_subdirectory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to split data from glaucoma & normal folders\n",
    "def split_data(source_dir, train_dir, val_dir, split_size):\n",
    "    source_files = os.listdir(source_dir)\n",
    "\n",
    "    # Ensure there are non-empty files\n",
    "    files_to_copy = []\n",
    "\n",
    "    for file_path in source_files:\n",
    "        if os.path.getsize(os.path.join(source_dir, file_path)) > 0:\n",
    "            files_to_copy.append(file_path)\n",
    "\n",
    "    # Shuffle the files in the list for further random selection\n",
    "    files_to_copy = random.sample(files_to_copy, len(files_to_copy))\n",
    "\n",
    "    # Remove previous files from training & validation folders\n",
    "    for file_path in os.listdir(train_dir):\n",
    "        os.remove(os.path.join(train_dir, file_path))\n",
    "\n",
    "    for file_path in os.listdir(val_dir):\n",
    "        os.remove(os.path.join(val_dir, file_path))\n",
    "\n",
    "    # Copy files to the training & validation set\n",
    "    training_size = int(split_size * len(files_to_copy))\n",
    "    for i in range(0, training_size):\n",
    "        source_path = os.path.join(source_dir, files_to_copy[i])\n",
    "        destination_path = os.path.join(train_dir, files_to_copy[i])\n",
    "        shutil.copyfile(source_path, destination_path) \n",
    "\n",
    "    for i in range(training_size, len(files_to_copy)):\n",
    "        source_path = os.path.join(source_dir, files_to_copy[i])\n",
    "        destination_path = os.path.join(val_dir, files_to_copy[i])\n",
    "        shutil.copyfile(source_path, destination_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the glaucoma files into the train & validation datasets\n",
    "glaucoma_dir = os.path.join(acrima_dir, \"glaucoma\")\n",
    "glaucoma_train_dir = os.path.join(acrima_dir, \"train/glaucoma\")\n",
    "glaucoma_val_dir = os.path.join(acrima_dir, \"validation/glaucoma\")\n",
    "\n",
    "# We will use a 80% split size initially\n",
    "split_size = 0.8\n",
    "split_data(glaucoma_dir, glaucoma_train_dir, glaucoma_val_dir, split_size=split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the normal files into the train & validation datasets\n",
    "normal_dir = os.path.join(acrima_dir, \"normal\")\n",
    "normal_train_dir = os.path.join(acrima_dir, \"train/normal\")\n",
    "normal_val_dir = os.path.join(acrima_dir, \"validation/normal\")\n",
    "\n",
    "# We'll use the same split size\n",
    "split_data(normal_dir, normal_train_dir, normal_val_dir, split_size=split_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image generators for the training & validation data\n",
    "def image_generators(train_dir, val_dir, train_img_size, val_img_size):\n",
    "  \"\"\"\n",
    "  Inputs:\n",
    "  train_dir = training data directory\n",
    "  val_dir = validation data directory\n",
    "  train_img_size = the size of the training input images (tuple)\n",
    "  val_img_size = the size of the validation input images (tuple)\n",
    "\n",
    "  Outputs:\n",
    "  train_generator = image generator for training data\n",
    "  val_generator = image generator for validation data\n",
    "  \"\"\"\n",
    "\n",
    "  # Instatiate ImageGenerator & rescale\n",
    "  train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "  val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "  # Apply the ImageGenerator to the training & validation datasets\n",
    "  train_generator = train_datagen.flow_from_directory(directory=train_dir,\n",
    "                                                      batch_size=20,\n",
    "                                                      class_mode='binary',\n",
    "                                                      target_size=train_img_size)\n",
    "\n",
    "  val_generator = val_datagen.flow_from_directory(directory=val_dir,\n",
    "                                                                batch_size=20,\n",
    "                                                                class_mode='binary',\n",
    "                                                                target_size=val_img_size)\n",
    "  \n",
    "  return train_generator, val_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions are also saved in `utils.py` for use in later notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
