{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simple CNN models\n",
    "\n",
    "In this notebook, we'll deploy and analyze the results of simple CNNs on our training, validation & testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from utils import split_data, image_generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Define & choose network architecture\n",
    "\n",
    "We'll create, visualize, and evaluate 3 different CNN architectures:\n",
    "* 1 x convolutional, 1 x pooling, 1 x dense layers\n",
    "- 2 x convolutional, 2 x pooling, 1 x dense layers\n",
    "* 3 x convolutional, 3 x pooling, 1 x dense layers\n",
    "\n",
    "We want to find the optimal number of convolutions for increasing the accuracy of our predictions without losing information from the dataset. We will also test how our performance is affected when we remove any of the pooling layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off, we'll define the image size for the training and validation data as (178, 178), as it's the smallest resolution from the whole dataset. Secondly, we'll do a 80-20 train-validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = 0.8\n",
    "\n",
    "# Save directory paths\n",
    "acrima_dir = os.path.join(os.getcwd(), \"data/acrima-dataset\")\n",
    "glaucoma_dir = os.path.join(acrima_dir, \"glaucoma\")\n",
    "normal_dir = os.path.join(acrima_dir, \"normal\")\n",
    "train_dir = os.path.join(acrima_dir, \"train\")\n",
    "val_dir = os.path.join(acrima_dir, \"validation\")\n",
    "g_train_dir = os.path.join(train_dir, \"glaucoma\")\n",
    "g_val_dir = os.path.join(val_dir, \"glaucoma\")\n",
    "n_train_dir = os.path.join(train_dir, \"normal\")\n",
    "n_val_dir = os.path.join(val_dir, \"normal\")\n",
    "\n",
    "# Train-validation split data\n",
    "split_data(glaucoma_dir, g_train_dir, g_val_dir, split_size)\n",
    "split_data(normal_dir, n_train_dir, n_val_dir, split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 563 images belonging to 2 classes.\n",
      "Found 142 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define input datasets arguments\n",
    "train_image_size = (178, 178)\n",
    "val_image_size = (178, 178)\n",
    "\n",
    "# Get image generators for training & validation data\n",
    "train_gen, val_gen = image_generators(train_dir, val_dir, train_image_size, val_image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll check to see how well each of the models is performing after 15 epochs to then choose a model to refine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (178, 178, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1. One layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_layer_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), input_shape=input_shape, activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "one_layer_model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\\\n",
    "    loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = one_layer_model.fit(train_gen,\n",
    "                    epochs=15,\n",
    "                    verbose=1,\n",
    "                    validation_data=val_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2. Two-layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_layer_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), input_shape=train_image_size, activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), input_shape=train_image_size, activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "two_layer_model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\\\n",
    "    loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3. Three-layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_layer_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), input_shape=train_image_size, activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), input_shape=train_image_size, activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), input_shape=train_image_size, activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "three_layer_model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\\\n",
    "    loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
