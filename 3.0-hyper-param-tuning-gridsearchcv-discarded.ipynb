{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import image_generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to GDrive files\n",
    "drive = \"drive/MyDrive\"\n",
    "\n",
    "# Save directory paths\n",
    "train_dir = os.path.join(drive, \"train\")\n",
    "val_dir = os.path.join(drive, \"validation\")\n",
    "g_train_dir = os.path.join(train_dir, \"glaucoma\")\n",
    "g_val_dir = os.path.join(val_dir, \"glaucoma\")\n",
    "n_train_dir = os.path.join(train_dir, \"normal\")\n",
    "n_val_dir = os.path.join(val_dir, \"normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input datasets arguments\n",
    "train_image_size = (178, 178)\n",
    "val_image_size = (178, 178)\n",
    "\n",
    "# Get image generators for training & validation data\n",
    "train_gen, val_gen = image_generators(train_dir, val_dir, train_image_size, val_image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3lWWyTZBCx8"
   },
   "source": [
    "#### 3.2.0. Hyperparameter tuning with GridSearchCV (discarded because of runtime issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VvhgQ6Fh2q2e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5EvbkHxzC7h_"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  two_layer_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), input_shape=(178, 178, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "  two_layer_model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\\\n",
    "    loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  \n",
    "  return two_layer_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LsWBC6tHFUpb"
   },
   "source": [
    "To use GridSearchCV with our image generators we need to unwrap the augmented images from the generators. To do so, I explored the `train_gen` `keras.preprocessing.image.DirectoryIterator` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IC9Eut_kDZ94",
    "outputId": "757c07aa-20f0-4340-b58c-291b2371af47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_gen type: <class 'keras.preprocessing.image.DirectoryIterator'>\n",
      "train_gen[0] type <class 'tuple'>\n",
      "train_gen[0][0] type <class 'numpy.ndarray'>\n",
      "train_gen[0][0][0] type <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"train_gen type:\", type(train_gen))\n",
    "print(\"train_gen[0] type\", type(train_gen[0]))\n",
    "print(\"train_gen[0][0] type\", type(train_gen[0][0]))\n",
    "print(\"train_gen[0][0][0] type\", type(train_gen[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EKn1rj9cGEfr",
    "outputId": "2f738b81-b02f-49b5-e22e-b4f5aabcccba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_gen length: 29\n",
      "train_gen[0] length 2\n",
      "train_gen[0][0] shape (20, 178, 178, 3)\n",
      "train_gen[0][0][0] shape (178, 178, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_gen length:\", len(train_gen))\n",
    "print(\"train_gen[0] length\", len(train_gen[0]))\n",
    "print(\"train_gen[0][0] shape\", train_gen[0][0].shape)\n",
    "print(\"train_gen[0][0][0] shape\", train_gen[0][0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EmMZiSHsHOZu"
   },
   "source": [
    "We notice that each element in the `train_gen`corresponds to an image batch. Then, the elements in the `train_gen[x]` tuples contain each image and label within the batch. Therefore, we need to iterate through each sample to get the input augmented images and their label for `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5zm6ZJMjJbdA"
   },
   "outputs": [],
   "source": [
    "def extract_images(generator, classes={0: \"0\", 1:\"1\"}):\n",
    "\n",
    "  no_of_batches = len(generator)\n",
    "  no_of_classes = len(classes)\n",
    "  batch_size = generator[0][0].shape[0]\n",
    "  no_of_examples = no_of_batches * no_of_classes * batch_size\n",
    "\n",
    "  X = []\n",
    "  y = []\n",
    "\n",
    "  for no_batch, batch in tqdm(enumerate(generator)):\n",
    "\n",
    "    # Ensure iteration doesn't run indefinitely, it's a keras issue\n",
    "    if no_batch > (no_of_batches - 1):\n",
    "      break\n",
    "\n",
    "    for (image, label) in zip(batch[0], batch[1]):\n",
    "      X.append(image)\n",
    "      y.append(classes[label])\n",
    "\n",
    "  return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "giYtsI1nNqAd",
    "outputId": "79e2e403-ae88-44e9-f1d7-d772fb4eacf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'glaucoma': 0, 'normal': 1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Figure out which class is 0 and which is 1\n",
    "train_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hdXdyswmNigJ",
    "outputId": "63ae6ec8-b3c3-468c-f2e5-0da04e8f9343"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29it [00:04,  6.30it/s]\n",
      "8it [00:01,  6.17it/s]\n"
     ]
    }
   ],
   "source": [
    "classes = {0: \"glaucoma\", 1: \"normal\"}\n",
    "\n",
    "X_train, y_train = extract_images(train_gen, classes)\n",
    "X_val, y_val = extract_images(val_gen, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jYnP13UBOplS",
    "outputId": "5ff1cdb5-fb8b-4e73-98ea-7593b2002baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705\n",
      "(178, 178, 3)\n",
      "705\n",
      "glaucoma\n"
     ]
    }
   ],
   "source": [
    "# Group all training data together\n",
    "X = X_train + X_val\n",
    "y = y_train + y_val\n",
    "\n",
    "# Ensure we have the correct format and number of samples\n",
    "print(len(X))\n",
    "print(X[0].shape)\n",
    "print(len(y))\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GANntdCVMfL8"
   },
   "outputs": [],
   "source": [
    "# Choose a random seed for reproducibility\n",
    "seed = 7\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Define the grid search parameters\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 20, 30, 40, 50]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=create_model(), param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
